{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Econometrics - Assignment 2\n",
    "**Marta Batíková, Matěj Kovář, Petr Pham** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: sandwich\n",
      "Loading required package: miscTools\n",
      "\n",
      "Please cite the 'maxLik' package as:\n",
      "Henningsen, Arne and Toomet, Ott (2011). maxLik: A package for maximum likelihood estimation in R. Computational Statistics 26(3), 443-458. DOI 10.1007/s00180-010-0217-1.\n",
      "\n",
      "If you have questions, suggestions, or comments regarding the 'maxLik' package, please use a forum or 'tracker' at maxLik's R-Forge site:\n",
      "https://r-forge.r-project.org/projects/maxlik/\n"
     ]
    }
   ],
   "source": [
    "library(gmm)\n",
    "library(maxLik)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Specification of two sample moment conditions\n",
    "Given the two moment conditions about mean and variance of a $\\chi^2$ distribution with $d$ degress of freedom. The vector of moments conditions is the following\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "E[g(\\theta,x_i)] \\equiv E \\left[ \\begin{array}{c}\n",
    "d-x_i\\\\\n",
    "2d - (x_i-d)^2 \\\\\\end{array} \\right]=0\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) + c) Sample simulation, GMM estimation,  $J$-test, verification of moment conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling 500 points from the chi-squared distribution with 1 degree of freedom\n",
    "set.seed(666)\n",
    "data <- rchisq(n=500, df = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the two sample moment conditions as we have specified above are specified as following\n",
    "gmmcond = function(d, x) {\n",
    "    sm1 = (d-x)\n",
    "    sm2 = (2*d-(x-d)^2)\n",
    "    cond = cbind(sm1,sm2)\n",
    "    return(cond) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "gmm(g = gmmcond, x = data, t0 = c(d = 0), wmatrix = \"optimal\", \n",
       "    vcov = \"HAC\", kernel = \"Truncated\", optfct = \"nlminb\")\n",
       "\n",
       "\n",
       "Method:  twoStep \n",
       "\n",
       "Kernel:  Truncated(with bw =  0.3442 )\n",
       "\n",
       "Coefficients:\n",
       "   Estimate    Std. Error  t value     Pr(>|t|)  \n",
       "d  9.9742e-01  5.0340e-02  1.9814e+01  2.2638e-87\n",
       "\n",
       "J-Test: degrees of freedom is 1 \n",
       "                J-test   P-value\n",
       "Test E(g)=0:    0.27665  0.59891\n",
       "\n",
       "Initial values of the coefficients\n",
       "       d \n",
       "1.060125 \n",
       "\n",
       "#############\n",
       "Information related to the numerical optimization\n",
       "Convergence code =  0 \n",
       "Function eval. =  6 \n",
       "Gradian eval. =  8 \n",
       "Message:  both X-convergence and relative convergence (5) "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Estimation of 1 degree of freedom with and optimal weighting matrix\n",
    "gmmopti <- gmm(gmmcond, data, t0 = c(d=0), wmatrix = \"optimal\", optfct = \"nlminb\", kernel = \"Truncated\", vcov = \"HAC\")\n",
    "summary(gmmopti)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the $J$-test, the estimated model using an optimal weighting matrix is well specified. We cannot reject the null hypothesis as the p-value is rather large. The $H_0$ states that the value of the objective function is different from zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "gmm(g = gmmcond, x = data, t0 = c(d = 0), wmatrix = \"ident\", \n",
       "    vcov = \"HAC\", kernel = \"Truncated\", optfct = \"nlminb\")\n",
       "\n",
       "\n",
       "Method:  One step GMM with W = identity \n",
       "\n",
       "Kernel:  Truncated\n",
       "\n",
       "Coefficients:\n",
       "   Estimate    Std. Error  t value     Pr(>|t|)  \n",
       "d  1.0601e+00  1.3370e-01  7.9293e+00  2.2043e-15\n",
       "\n",
       "J-Test: degrees of freedom is 1 \n",
       "                J-test   P-value\n",
       "Test E(g)=0:    1.81566  0.17783\n",
       "\n",
       "#############\n",
       "Information related to the numerical optimization\n",
       "Convergence code =  0 \n",
       "Function eval. =  8 \n",
       "Gradian eval. =  10 \n",
       "Message:  both X-convergence and relative convergence (5) "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Estimation of 1 degree of freedom with and identity weighting matrix\n",
    "gmmiden <- gmm(gmmcond, data, t0 = c(d=0), wmatrix = \"ident\", optfct = \"nlminb\", kernel = \"Truncated\", vcov = \"HAC\")\n",
    "summary(gmmiden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the $J$-test, the estimated model using an identity weighting is still well specified. Thus, we can not reject the null hypothesis $H_0$ that the value of the objective function is different from zero. Yet in comparison with the previous model, the p-value is significantly lower (0.60 vs. 0.18)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Comparison of MM, GMM and MLE methods using simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two sample conditions were already defined (gmmcond function). In order to obtain the simple MM estimator, we will have to define a function with a sole sample condition (mmcond). Lastly, we will define the following log-likelihood function for the chi-squared distribution in order obtain the ML estimator.\n",
    "\n",
    "\\begin{align}\n",
    "log(L(k)) & =  \\log{\\left(\\prod_{i=1}^n f(x_i;k)\\right)}\\\\\n",
    "          & =  \\sum_{i=1}^n \\log{\\left(\\frac{x_i^{k/2-1}e^{-x_i/2}}{\\Gamma(k/2)2^{k/2}}\\right)}\\\\\n",
    "          & =  \\big(\\frac{k}{2}-1\\big)\\sum_{i=1}^n\\log{x_i} - \\frac{1}{2}\\sum_{i=1}^nx_i - n\\log(\\Gamma(k/2)) - \\frac{nk}{2}\\log(2)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample moment condition for MM estimator\n",
    "mmcond = function(d, x) {\n",
    "    sm1 = (d-x)\n",
    "    return(sm1) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation function including statistics and distribution of each estimator\n",
    "\n",
    "simulatechisq <- function(n = 100, iterations = 10) {\n",
    "   mat <- matrix(0, iterations, 4) # empty matrix for faster results\n",
    "   \n",
    "   # log-likelihood function (nested inside the outer function as samples are obtained locally)\n",
    "   logLikFun <- function(param) {\n",
    "    if (param <= 0) {\n",
    "      return(NA)\n",
    "    }\n",
    "      return(((param/2)-1)*sum(log(data)) - (0.5 * sum(data)) - n * log(gamma(param/2)) - (n*param) * 0.5 * log(2))\n",
    "   }  \n",
    "    \n",
    "   for(i in 1 : iterations){\n",
    " \n",
    "       data <- rchisq(n, df = 1) # generation of data from a chisquare distribution with 1 df\n",
    "       #Method of moments estimator\n",
    "       mat[i, 1] <- gmm(mmcond, data, t0 = c(d=0), optfct = \"nlminb\", kernel = \"Truncated\", vcov = \"HAC\")$coefficients  \n",
    "       #General method of moments estimator using an identity weighting matrix\n",
    "       mat[i, 2] <- gmm(gmmcond, data, t0 = c(d=0), wmatrix = \"ident\", optfct = \"nlminb\", kernel = \"Truncated\", vcov = \"HAC\")$coefficients  \n",
    "       #General method of moments estimator using an optimal weighting matrix\n",
    "       mat[i, 3] <- gmm(gmmcond, data, t0 = c(d=0), wmatrix = \"optimal\", optfct = \"nlminb\", kernel = \"Truncated\", vcov = \"HAC\")$coefficients  \n",
    "       #Maximum-likelihood estimator\n",
    "       mat[i, 4] <- maxLik(logLikFun, start = c(d=0.1))$estimate\n",
    "       \n",
    "   }\n",
    "\n",
    "   par(mfcol=c(2,2), oma=c(0,0,2,0)) # Ordering of histograms  \n",
    "   \n",
    "   hist(mat[, 1], breaks = seq(0.6, 1.4, by = 0.05), main = \"a) MM estimator\", xlab = \"Estimated mean\")\n",
    "   hist(mat[, 2], main = \"b) GMM estimator with identity WM\", xlab = \"Estimated mean\")\n",
    "   hist(mat[, 3], breaks = seq(0.6, 1.4, by = 0.05), main = \"c) GMM estimator with optimal WM\", xlab = \"Estimated mean\")\n",
    "   hist(mat[, 4], breaks = seq(0.6, 1.4, by = 0.05), main = \"d) MLE estimator\", xlab = \"Estimated mean\")\n",
    "   \n",
    "    title(cat(\n",
    "       paste(\"Comparison of MM, GMMs and MLE estimated parameters \"), \n",
    "       paste(\"Sample size = \", n,\", \", iterations, \" iterations\", sep = \"\")\n",
    "       , sep=\"\\n\"), outer = TRUE) \n",
    "    \n",
    "   statistics <- rbind(t(matrix(colMeans(mat))), t(matrix(colMeans(mat))) - 1, diag(var(mat)))\n",
    "   dimnames(statistics) <- list(c(\"Mean\", \"Bias\", \"Variance\"),\n",
    "                       c(\"MM estimator\",\"GMM estimator with identity WM\", \"GMM estimator with optimal WM\", \"MLE estimator\"))\n",
    "   return(statistics)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of MM, GMMs and MLE estimated parameters \n",
      "Sample size = 500, 1000 iterations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>MM estimator</th><th scope=col>GMM estimator with identity WM</th><th scope=col>GMM estimator with optimal WM</th><th scope=col>MLE estimator</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Mean</th><td> 0.997878654 </td><td> 0.9994482052</td><td>1.003048912  </td><td> 0.9997080632</td></tr>\n",
       "\t<tr><th scope=row>Bias</th><td>-0.002121346 </td><td>-0.0005517948</td><td>0.003048912  </td><td>-0.0002919368</td></tr>\n",
       "\t<tr><th scope=row>Variance</th><td> 0.003943186 </td><td> 0.0179419657</td><td>0.003103055  </td><td> 0.0016070354</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       "  & MM estimator & GMM estimator with identity WM & GMM estimator with optimal WM & MLE estimator\\\\\n",
       "\\hline\n",
       "\tMean &  0.997878654  &  0.9994482052 & 1.003048912   &  0.9997080632\\\\\n",
       "\tBias & -0.002121346  & -0.0005517948 & 0.003048912   & -0.0002919368\\\\\n",
       "\tVariance &  0.003943186  &  0.0179419657 & 0.003103055   &  0.0016070354\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | MM estimator | GMM estimator with identity WM | GMM estimator with optimal WM | MLE estimator |\n",
       "|---|---|---|---|---|\n",
       "| Mean |  0.997878654  |  0.9994482052 | 1.003048912   |  0.9997080632 |\n",
       "| Bias | -0.002121346  | -0.0005517948 | 0.003048912   | -0.0002919368 |\n",
       "| Variance |  0.003943186  |  0.0179419657 | 0.003103055   |  0.0016070354 |\n",
       "\n"
      ],
      "text/plain": [
       "         MM estimator GMM estimator with identity WM\n",
       "Mean      0.997878654  0.9994482052                 \n",
       "Bias     -0.002121346 -0.0005517948                 \n",
       "Variance  0.003943186  0.0179419657                 \n",
       "         GMM estimator with optimal WM MLE estimator\n",
       "Mean     1.003048912                    0.9997080632\n",
       "Bias     0.003048912                   -0.0002919368\n",
       "Variance 0.003103055                    0.0016070354"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nQmCC",
      "text/plain": [
       "Plot with title \"d) MLE estimator\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(scipen = 100)\n",
    "simulatechisq(n = 500, iterations = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of estimators\n",
    "Out of the four estimators, MLE is the most efficient estimator with the lowest bias and certainly the lowest variance. This is not a surprising result as MLE was simply able to use the additional information about the distribution. On the other hand, the remaining estimators do not need such assumption as thus did not make use of it. \n",
    "\n",
    "The second best is the MM estimator with a sole condition. Surprisingly for our chosen number of points (500) and number of iterations (1000), it is better than both GMM estimators, which seem to be \"confused\" with additional information. The GMM estimator with an identity weighting matrix, assigns the same weight for both conditions and does not take into account that the cost of the second condition is systematically be larger due to the specification of the second moment. Thus, as it is using one information more than the other, the bias is thus lower.\n",
    "\n",
    "Given our simulation parameters, the worst estimator of all four is the GMM estimator with optimal weighting matrix, which is rather unexpected. It seems that the assymptotic properties are genuinely assymptotic as n of 500 is simply not enough. The bias of the estimator is larger than its variance. The variance is however the second lowest and assymptotically this would be the second best estimator of the four."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
